# title_validator.py
# Heurystyczna walidacja tytu≈Ç√≥w dla r/CShortDramas
# Cel: wychwyciƒá brak nazwy/opisu w üìå Link Request (np. "Need help finding title or link"),
#      ale nie karaƒá prawid≈Çowych, kr√≥tkich tytu≈Ç√≥w typu "The stand-in".

from __future__ import annotations
import re
import unicodedata
from typing import Dict, List, Set

# ----------------------------- S≈Çowniki / wzorce -----------------------------

# S≈Çowa nie-niosƒÖce informacji (po normalizacji, lower-case)
GENERIC_STOPWORDS: Set[str] = {
    # og√≥lne pro≈õby/s≈Çowa serwisowe
    "need", "needs", "help", "please", "pls", "plz", "anyone", "someone", "anybody",
    "trying", "try", "find", "finding", "look", "looking", "search", "searching",
    "title", "name", "link", "links", "id", "identify", "identification",
    "this", "that", "it", "one", "what", "which",
    # domenowe og√≥lniki
    "drama", "show", "series", "movie", "short", "shorts", "micro", "episode", "episodes",
    "english", "eng", "subs", "subtitle", "subtitles",
    # platformy / og√≥lniki
    "douyin", "tiktok", "youtube", "yt", "bilibili", "xiaohongshu", "xhs",
    # sp√≥jniki/zaimki itp.
    "a", "an", "the", "and", "or", "of", "for", "to", "in", "on", "at", "with",
    "is", "are", "was", "were", "be", "been", "being",
    "my", "your", "their", "his", "her", "our",
    "please,", "please.", "help.", "help,",  # czasem po znakach
}

# S≈Çowa ‚Äûpodejrzane‚Äù w ultra-kr√≥tkich tytu≈Çach
SUSPECT_HINTS: Set[str] = {
    "help", "title", "link", "looking", "need", "pls", "please", "find", "finding"
}

# Wyra≈ºenia typu ‚Äûpusta pro≈õba‚Äù ‚Äì je≈õli pasuje i brak innych sygna≈Ç√≥w ‚Üí MISSING
GENERIC_TITLE_PATTERNS: List[re.Pattern] = [
    re.compile(r"\bneed\s+help\b", re.I),
    re.compile(r"\bhelp\s+me\b", re.I),
    re.compile(r"\bhelp\b.*\bfind(ing)?\b", re.I),
    re.compile(r"\bfind(ing)?\b.*\btitle\b", re.I),
    re.compile(r"\b(title|name)\b.*\blink\b", re.I),
    re.compile(r"\blooking\s+for\b", re.I),
    re.compile(r"\bany(one|body)\b.*\bknow\b", re.I),
    re.compile(r"\bdoes\s+anyone\s+know\s+(its|the)\s+name\b", re.I),
    re.compile(r"\banyone\s+know\s+(the\s+)?name\b", re.I),
    
    # Zaktualizowane wzorce dla ‚Äûlooking for‚Äù:
    re.compile(r"\blooking\s+for\s+(title|link)\b", re.I),  # Puste zapytania: looking for title/link

    # --- NOWE wzorce: ‚Äûwhere ‚Ä¶ watch/find‚Äù ---
    re.compile(r"\bwhere\s+(can\s+)?(i\s+)?watch\b", re.I),   # where (can i) watch
    re.compile(r"\bwhere\s+to\s+watch\b", re.I),              # where to watch
    re.compile(r"\bwhere\s+(can\s+)?(i\s+)?find\b", re.I),    # where (can i) find

    # --- nowe: "don't know the name/title" (r√≥wnie≈º z apostrofem ‚Äô) ---
    re.compile(r"\b(i\s+)?do(?:n'?|‚Äô)?t\s+know\s+(the\s+)?(title|name)\b", re.I),
    re.compile(r"\b(i\s+)?do\s+not\s+know\s+(the\s+)?(title|name)\b", re.I),
    re.compile(r"\bunknown\s+(title|name)\b", re.I),

]

# Flairy, dla kt√≥rych wymagamy faktycznej nazwy/opisu (pe≈Çna surowo≈õƒá)
STRICT_FLAIRS = {"üìå Link Request"}

# ----------------------------- Normalizacja / tokeny -----------------------------

def _nfkc(s: str) -> str:
    return unicodedata.normalize("NFKC", s)

def _normalize_text(s: str) -> str:
    s = _nfkc(s or "")
    # Usuwamy nadmiarowƒÖ interpunkcjƒô (zachowujemy cyfry/litery/CJK i my≈õlnik w ≈õrodku s≈Çowa)
    s = re.sub(r"[^\w\s\-\,\.\u4e00-\u9fff\u3040-\u30ff]", " ", s, flags=re.UNICODE)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def _tokens(s: str) -> List[str]:
    if not s:
        return []
    return [t for t in s.split() if t]

def _ltoken(t: str) -> str:
    return t.lower()

def _informative_tokens(tokens: List[str]) -> List[str]:
    return [t for t in map(_ltoken, tokens) if t not in GENERIC_STOPWORDS and len(t) >= 2]

# ----------------------------- Heurystyki wykrywania -----------------------------

def _has_strong_signal(tokens: List[str]) -> bool:
    """
    Silne sygna≈Çy, ≈ºe tytu≈Ç niesie konkretnƒÖ informacjƒô:
    - znaki CJK (czƒôsto prawdziwa nazwa),
    - numer identyfikacyjny / rok / 4+ cyfry (np. 11735),
    - mix liter i cyfr (np. s02e03, ep10),
    - co najmniej 2 sensowne tokeny (>=4 znaki) po odciƒôciu stopword√≥w.
    """
    s = " ".join(tokens)
    if re.search(r"[\u4e00-\u9fff\u3040-\u30ff]", s):
        return True
    if any(re.fullmatch(r"\d{4,}", t) for t in tokens):
        return True
    if any(re.search(r"[A-Za-z]\d|\d[A-Za-z]", t) for t in tokens):
        return True
    informative = _informative_tokens(tokens)
    if sum(1 for t in informative if len(t) >= 4) >= 2:
        return True
    return False

def _token_is_hyphen_title(tok: str) -> bool:
    # np. "Stand-in", "Re-born" ‚Äî my≈õlnik w rdzeniu, nie prefiks/sufiks
    return bool(re.fullmatch(r"[A-Za-z]{2,}\-[A-Za-z]{2,}", tok))

def _titlecase_ratio(tokens: List[str]) -> float:
    if not tokens:
        return 0.0
    tc = 0
    for t in tokens:
        if len(t) >= 2 and t[0].isalpha() and t[0].upper() == t[0]:
            tc += 1
    return tc / max(1, len(tokens))

def _has_suspect_word(tokens: List[str]) -> bool:
    tl = [t.lower() for t in tokens]
    return any(t in SUSPECT_HINTS for t in tl)

def _looks_like_generic_request(s_norm: str) -> bool:
    return any(p.search(s_norm) for p in GENERIC_TITLE_PATTERNS)

# ----------------------------- Inquiry: generica -----------------------------

def is_generic_inquiry(title: str) -> bool:
    """
    True, je≈õli tytu≈Ç wyglƒÖda na ‚ÄûpustƒÖ pro≈õbƒô‚Äù (help/title/link/looking for...),
    a jednocze≈õnie nie zawiera silnych sygna≈Ç√≥w (np. 11735, CJK, litera+cyfra).
    U≈ºywane wy≈ÇƒÖcznie dla flair√≥w Inquiry.
    """
    title_raw = (title or "").strip()
    if not title_raw:
        return True  # pusty = ewidentnie z≈Çy

    title_norm = _normalize_text(title_raw)
    toks = _tokens(title_norm)

    # Je≈ºeli w og√≥le nie ma token√≥w po normalizacji, traktujemy jako puste
    if not toks:
        return True

    # Je≈õli sƒÖ ‚Äûsilne sygna≈Çy‚Äù, nie kwalifikujemy jako 'generic inquiry'
    if _has_strong_signal(toks):
        return False

    # Typowe puste wzorce (need help / help me / looking for / find title / title+link)
    if _looks_like_generic_request(title_norm):
        return True

    # Ultra-kr√≥tkie tytu≈Çy zawierajƒÖce s≈Çowa podejrzane (help/title/link/please/looking‚Ä¶)
    if _has_suspect_word(toks):
        # brak silnych sygna≈Ç√≥w + podejrzane s≈Çowo ‚Üí generica
        return True

    return False

# ----------------------------- Link Request: generica -----------------------------

def _looks_like_generic_placeholder(title: str) -> bool:
    """
    Wykrywa puste/og√≥lne tytu≈Çy typu: 'Does anyone know its name?', 'Please link', 'Need title', itp.
    Zostawia wyjƒÖtki (CJK / 4+ cyfry / s02e03 / ep12 / tytu≈Ç w cudzys≈Çowie), kt√≥re sugerujƒÖ konkretny trop.
    """
    if not title:
        return True

    t_raw = title.strip()
    t_norm = _normalize_text(t_raw)
    toks = _tokens(t_norm)

    # ----- mocne wyjƒÖtki (NIE oznaczamy jako generic) -----
    if not toks:
        return True  # puste po normalizacji
    if _has_strong_signal(toks):
        return False
    # tytu≈Ç w cudzys≈Çowie (np. "Love Beyond Fate")
    if re.search(r"[\"‚Äú][^\"‚Äú]{3,}?[\"‚Äù]", t_raw):
        return False

    # ----- klasyczne puste wzorce -----
    if _looks_like_generic_request(t_norm):
        return True

    # bardzo ma≈Ço tre≈õci informacyjnej (‚â§2 tokeny sensowne) + podejrzane s≈Çowa
    informative = _informative_tokens(toks)
    if len(informative) <= 2 and _has_suspect_word(toks):
        return True

    return False

# ----------------------------- Walidator g≈Ç√≥wny -----------------------------

def validate_title(title: str, flair: str = "", config: Dict = None) -> Dict[str, str]:
    """
    Zwraca dict: {"status": "OK|AMBIGUOUS|MISSING", "reason": "<kr√≥tki_pow√≥d>"}.
    Zmiany (kompromis dla kr√≥tkich tytu≈Ç√≥w):
      - Je≈õli wyglƒÖda jak prawdziwy tytu≈Ç (hyphen w rdzeniu albo TitleCase przy ‚â§3 s≈Çowach),
        przepuszczamy jako OK.
      - Je≈õli tytu≈Ç jest bardzo kr√≥tki, ale ‚Äûczysty‚Äù (bez podejrzanych s≈Ç√≥w) i ma ‚â•1 sensowny token (‚â•4 litery),
        to AMBIGUOUS (trafi do MOD_QUEUE), nie MISSING.
      - ‚ÄûHelp/link/title/please‚Ä¶‚Äù nadal klasyfikujƒÖ jako MISSING, o ile brak silnych sygna≈Ç√≥w.
    """
    flair = (flair or "").strip()
    title_raw = (title or "").strip()

    # üìå Link Request ‚Üí najpierw odsie≈Ñ ‚Äûpuste/generic‚Äù tytu≈Çy
    if flair == "üìå Link Request":
        if _looks_like_generic_placeholder(title_raw):
            return {"status": "MISSING", "reason": "generic_placeholder"}

    # Puste pozycje ≈Çapiemy zawsze
    if not title_raw:
        return {"status": "MISSING", "reason": "empty_title"}

    title_norm = _normalize_text(title_raw)
    toks = _tokens(title_norm)
    if not toks:
        return {"status": "MISSING", "reason": "empty_after_norm"}

    informative = _informative_tokens(toks)

    # Sztywne ‚Äûpuste pro≈õby‚Äù dla ≈õcis≈Çych flair√≥w, je≈õli brak silnych sygna≈Ç√≥w
    if flair in STRICT_FLAIRS:
        if _looks_like_generic_request(title_norm) and not _has_strong_signal(toks):
            return {"status": "MISSING", "reason": "generic_title"}

    # Heurystyki ratunkowe dla kr√≥tkich tytu≈Ç√≥w
    words_cnt = len(toks)
    has_hyphen_title = any(_token_is_hyphen_title(t) for t in toks)
    titlecase_ratio = _titlecase_ratio(toks)
    has_suspect = _has_suspect_word(toks)
    has_strong = _has_strong_signal(toks)
    long_informative = [t for t in informative if len(t) >= 4]

    if flair in STRICT_FLAIRS:
        # 1) WyglƒÖda jak tytu≈Ç ‚Üí OK
        #    - token z my≈õlnikiem (stand-in)
        #    - ‚â§3 s≈Çowa, ‚â•1 sensowny token (‚â•4 litery) i >=50% TitleCase
        if has_hyphen_title or (words_cnt <= 3 and len(long_informative) >= 1 and titlecase_ratio >= 0.5):
            return {"status": "OK", "reason": "looks_like_title"}

        # 2) Kr√≥tkie, ale czyste ‚Üí AMBIGUOUS (do MOD_QUEUE), o ile brak podejrzanych s≈Ç√≥w
        if not has_strong and len(informative) < 2:
            if not has_suspect and len(long_informative) >= 1:
                return {"status": "AMBIGUOUS", "reason": "short_but_clean"}
            # 3) Je≈õli nadal brak mocnych sygna≈Ç√≥w i tytu≈Ç jest ‚Äûpusty‚Äù ‚Üí MISSING
            return {"status": "MISSING", "reason": "generic_title"}

        # 4) W pozosta≈Çych przypadkach ‚Äî OK (bo mamy ju≈º do≈õƒá sygna≈Ç√≥w)
        return {"status": "OK", "reason": "title_candidate"}

    else:
        # ≈Åagodniejsze zasady dla innych flair√≥w (np. Inquiry)
        if len(informative) == 0 and not has_strong:
            return {"status": "AMBIGUOUS", "reason": "uninformative"}
        return {"status": "OK", "reason": "title_candidate"}
